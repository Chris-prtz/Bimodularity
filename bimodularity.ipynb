{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdf887f5",
   "metadata": {},
   "source": [
    "# Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9991453c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import importlib\n",
    "\n",
    "import dgsp\n",
    "import Bimodularity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec82de12",
   "metadata": {},
   "source": [
    "# _C. elegans_ bicommunities (Figure 4) (from bimodularity-Figures.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e8c834",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_sex = False\n",
    "gap_junc = False\n",
    "\n",
    "wiring_sym = np.genfromtxt(\"./data/celegans_graph\"+gap_junc*\"_GAP\"+\".csv\", delimiter=\",\")\n",
    "neuron_df = pd.read_csv(\"./data/celegans_neurons.csv\")\n",
    "\n",
    "wiring_mod = dgsp.modularity_matrix(wiring_sym, null_model=\"outin\")\n",
    "print(f\"Asymmetric wiring matrix has shape {wiring_sym.shape}\")\n",
    "\n",
    "nodes_labels = neuron_df.loc[:, \"Neuron\"]\n",
    "nodes_posx = neuron_df.loc[:, \"Position x\"]\n",
    "nodes_posy = neuron_df.loc[:, \"Position y\"]\n",
    "\n",
    "d_mat = np.diag(wiring_sym.sum(axis=1))\n",
    "\n",
    "U, S, Vh = dgsp.sorted_SVD(wiring_mod, fix_negative=False)\n",
    "V = Vh.T\n",
    "\n",
    "sort_idx = np.flip(np.argsort(S))\n",
    "S = S[sort_idx]\n",
    "U = U[:, sort_idx]\n",
    "V = V[:, sort_idx]\n",
    "\n",
    "neuron_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e93eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "graph = wiring_sym\n",
    "\n",
    "U, S, Vh = dgsp.sorted_SVD(dgsp.modularity_matrix(graph, null_model=\"outin\"))\n",
    "V = Vh.T\n",
    "\n",
    "n_nodes = graph.shape[0]\n",
    "\n",
    "#vector_id_max = 4\n",
    "vector_id_max = 5\n",
    "n_kmeans = 5\n",
    "\n",
    "edge_clusters, edge_clusters_mat = dgsp.edge_bicommunities(graph, U, V, vector_id_max, method=\"kmeans\",\n",
    "                                                           n_kmeans=n_kmeans, verbose=True, max_k=10)\n",
    "n_clusters = np.max(edge_clusters)\n",
    "\n",
    "sending_communities, receiving_communities = dgsp.get_node_clusters(edge_clusters, edge_clusters_mat, method=\"bimodularity\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a890a5ff",
   "metadata": {},
   "source": [
    "# Conjugate matching and tolerance variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b3a79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Bimodularity.community_fit_w_tolerance(sending_communities, receiving_communities, 0.5)\n",
    "#conjugate matching\n",
    "fits = [(epsilon, Bimodularity.community_fit_w_tolerance(sending_communities, receiving_communities, epsilon)) for epsilon in np.linspace(0, 0.5, 1000)]\n",
    "\n",
    "# Plotting the results\n",
    "fig, axes = plt.subplots(2,2, figsize=(15, 6))\n",
    "                        \n",
    "axes[0, 0].plot([fit[0] for fit in fits], [len(fit[1][0][0]) for fit in fits], label='match count', color='blue')\n",
    "axes[0, 0].set_xlabel('tolerance (epsilon)')\n",
    "axes[0, 0].set_ylabel('match count')\n",
    "axes[0, 0].set_title('singular community Fit with Tolerance')\n",
    "axes[0, 0].legend()  \n",
    "axes[0, 1].plot([fit[0] for fit in fits], [len(fit[1][2][0]) for fit in fits], label='match count', color='red')\n",
    "axes[0, 1].set_xlabel('tolerance (epsilon)')   \n",
    "axes[0, 1].set_ylabel('match count')\n",
    "axes[0, 1].set_title('overall community Fit with Tolerance')\n",
    "axes[0, 1].legend()\n",
    "axes[1, 0].plot([fit[0] for fit in fits], [fit[1][1] for fit in fits], label=' total cost', color='blue')\n",
    "axes[1, 0].set_xlabel('tolerance (epsilon)')\n",
    "axes[1, 0].set_ylabel('total cost')\n",
    "axes[1, 0].set_title('singular Total Cost with Tolerance')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 1].plot([fit[0] for fit in fits], [fit[1][3] for fit in fits], label=' total cost', color='red')\n",
    "axes[1, 1].set_xlabel('tolerance (epsilon)')\n",
    "axes[1, 1].set_ylabel('total cost')\n",
    "axes[1, 1].set_title('overall Total Cost with Tolerance')\n",
    "axes[1, 1].legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfbd7fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 clusters !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=9.\n",
      "  warnings.warn(\n",
      "c:\\Users\\chris\\Desktop\\MIP Project\\Bimodularity\\dgsp.py:210: RuntimeWarning: invalid value encountered in divide\n",
      "  sending_communities / np.sum(edge_clusters_mat > 0, axis=1),\n",
      "c:\\Users\\chris\\Desktop\\MIP Project\\Bimodularity\\dgsp.py:215: RuntimeWarning: invalid value encountered in divide\n",
      "  receiving_communities / np.sum(edge_clusters_mat > 0, axis=0),\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "modify_adjacency_matrix() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 49\u001b[0m\n\u001b[0;32m     46\u001b[0m n_clusters \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmax(edge_clusters)\n\u001b[0;32m     48\u001b[0m sending_communities, receiving_communities \u001b[38;5;241m=\u001b[39m dgsp\u001b[38;5;241m.\u001b[39mget_node_clusters(edge_clusters, edge_clusters_mat, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbimodularity\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 49\u001b[0m sending_communities, receiving_communities \u001b[38;5;241m=\u001b[39m Bimodularity\u001b[38;5;241m.\u001b[39mmodify_adjacency_matrix(sending_communities, receiving_communities, gamma)\n\u001b[0;32m     50\u001b[0m communities\u001b[38;5;241m.\u001b[39mappend((gamma, sending_communities, receiving_communities))\n",
      "\u001b[1;31mTypeError\u001b[0m: modify_adjacency_matrix() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "gammas = np.linspace(1, 100, 100)\n",
    "\n",
    "communities = []\n",
    "\n",
    "for gamma in gammas:\n",
    "    importlib.reload(dgsp)\n",
    "\n",
    "    no_sex = False\n",
    "    gap_junc = False\n",
    "\n",
    "    wiring_sym = np.genfromtxt(\"./data/celegans_graph\"+gap_junc*\"_GAP\"+\".csv\", delimiter=\",\")\n",
    "    neuron_df = pd.read_csv(\"./data/celegans_neurons.csv\")\n",
    "\n",
    "    communities.append(wiring_sym)\n",
    "    wiring_mod = dgsp.modularity_matrix(wiring_sym, null_model=\"outin\")\n",
    "    #print(f\"Asymmetric wiring matrix has shape {wiring_sym.shape}\")\n",
    "\n",
    "    nodes_labels = neuron_df.loc[:, \"Neuron\"]\n",
    "    nodes_posx = neuron_df.loc[:, \"Position x\"]\n",
    "    nodes_posy = neuron_df.loc[:, \"Position y\"]\n",
    "\n",
    "    d_mat = np.diag(wiring_sym.sum(axis=1))\n",
    "\n",
    "    U, S, Vh = dgsp.sorted_SVD(wiring_mod, fix_negative=False)\n",
    "    V = Vh.T\n",
    "\n",
    "    sort_idx = np.flip(np.argsort(S))\n",
    "    S = S[sort_idx]\n",
    "    U = U[:, sort_idx]\n",
    "    V = V[:, sort_idx]\n",
    "\n",
    "        \n",
    "    graph = wiring_sym\n",
    "\n",
    "    U, S, Vh = dgsp.sorted_SVD(dgsp.modularity_matrix(graph, null_model=\"outin\"))\n",
    "    V = Vh.T\n",
    "\n",
    "    n_nodes = graph.shape[0]\n",
    "\n",
    "    #vector_id_max = 4\n",
    "    vector_id_max = 5\n",
    "    n_kmeans = 5\n",
    "\n",
    "    edge_clusters, edge_clusters_mat = dgsp.edge_bicommunities(graph, U, V, vector_id_max, method=\"kmeans\",\n",
    "                                                            n_kmeans=n_kmeans, verbose=True, max_k=10)\n",
    "    n_clusters = np.max(edge_clusters)\n",
    "\n",
    "    sending_communities, receiving_communities = dgsp.get_node_clusters(edge_clusters, edge_clusters_mat, method=\"bimodularity\")\n",
    "    sending_communities, receiving_communities = Bimodularity.modify_adjacency_matrix(sending_communities, gamma), Bimodularity.modify_adjacency_matrix(receiving_communities, gamma)\n",
    "    communities.append((gamma, sending_communities, receiving_communities))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c660bad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n",
      " 100 matches\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m             c \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m matches\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28mprint\u001b[39m(communities[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(communities[\u001b[38;5;241m2\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\chris\\anaconda3\\Lib\\site-packages\\debugpy\\_vendored\\pydevd\\_pydevd_bundle\\pydevd_frame.py:988\u001b[0m, in \u001b[0;36mPyDBFrame.trace_dispatch\u001b[1;34m(self, frame, event, arg)\u001b[0m\n\u001b[0;32m    986\u001b[0m \u001b[38;5;66;03m# if thread has a suspend flag, we suspend with a busy wait\u001b[39;00m\n\u001b[0;32m    987\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info\u001b[38;5;241m.\u001b[39mpydev_state \u001b[38;5;241m==\u001b[39m STATE_SUSPEND:\n\u001b[1;32m--> 988\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_wait_suspend(thread, frame, event, arg)\n\u001b[0;32m    989\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrace_dispatch\n\u001b[0;32m    990\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\chris\\anaconda3\\Lib\\site-packages\\debugpy\\_vendored\\pydevd\\_pydevd_bundle\\pydevd_frame.py:165\u001b[0m, in \u001b[0;36mPyDBFrame.do_wait_suspend\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_wait_suspend\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 165\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_args[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdo_wait_suspend(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\chris\\anaconda3\\Lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[0;32m   2067\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[0;32m   2069\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[1;32m-> 2070\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\n\u001b[0;32m   2072\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[0;32m   2075\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\chris\\anaconda3\\Lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[0;32m   2103\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_input_hook()\n\u001b[0;32m   2105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_internal_commands()\n\u001b[1;32m-> 2106\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m   2108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(frame)))\n\u001b[0;32m   2110\u001b[0m \u001b[38;5;66;03m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in communities:\n",
    "    c= 0\n",
    "    for j in communities: \n",
    "        if np.allclose(i,j):\n",
    "            c += 1\n",
    "\n",
    "    print(f\" {c} matches\")\n",
    "print(communities[0])\n",
    "print(communities[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01b2cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create heatmap of gamma vs tolerance with match count using pre-computed communities\n",
    "import seaborn as sns\n",
    "\n",
    "# Extract gamma values and communities from the pre-computed results\n",
    "gamma_values = gammas\n",
    "tolerance_range = np.linspace(0, 0.5, 50)  # More tolerance points for smoother heatmap\n",
    "\n",
    "print(f\"Using {len(communities)} pre-computed gamma values\")\n",
    "print(f\"Testing {len(tolerance_range)} tolerance values\")\n",
    "\n",
    "# Initialize arrays to store results\n",
    "singular_match_counts = np.zeros((len(communities), len(tolerance_range)))\n",
    "overall_match_counts = np.zeros((len(communities), len(tolerance_range)))\n",
    "\n",
    "print(\"Computing tolerance variations for each gamma...\")\n",
    "\n",
    "for i, (gamma, sending_communities, receiving_communities) in enumerate(communities):\n",
    "    if i % 10 == 0:  # Progress indicator\n",
    "        print(f\"Processing gamma {i+1}/{len(communities)}: {gamma:.3f}\")\n",
    "    \n",
    "    # Calculate match counts for different tolerance values using pre-computed communities\n",
    "    for j, tolerance in enumerate(tolerance_range):\n",
    "        fit_result = Bimodularity.community_fit_w_tolerance(sending_communities, receiving_communities, tolerance)\n",
    "        singular_match_counts[i, j] = len(fit_result[0][0])  # singular community match count\n",
    "        overall_match_counts[i, j] = len(fit_result[2][0])   # overall community match count\n",
    "\n",
    "print(\"Heatmap computation complete!\")\n",
    "\n",
    "# Create the heatmaps using matplotlib\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Singular community match count heatmap\n",
    "im1 = axes[0].imshow(singular_match_counts, cmap='viridis', aspect='auto', origin='lower')\n",
    "axes[0].set_title('Singular Community Match Count\\n(Gamma vs Tolerance)')\n",
    "axes[0].set_xlabel('Tolerance (epsilon)')\n",
    "axes[0].set_ylabel('Gamma')\n",
    "\n",
    "# Set tick labels for better readability\n",
    "n_gamma_ticks = 10\n",
    "n_tolerance_ticks = 10\n",
    "gamma_tick_indices = np.linspace(0, len(gamma_values)-1, n_gamma_ticks, dtype=int)\n",
    "tolerance_tick_indices = np.linspace(0, len(tolerance_range)-1, n_tolerance_ticks, dtype=int)\n",
    "\n",
    "axes[0].set_xticks(tolerance_tick_indices)\n",
    "axes[0].set_xticklabels([f'{tolerance_range[i]:.2f}' for i in tolerance_tick_indices])\n",
    "axes[0].set_yticks(gamma_tick_indices)\n",
    "axes[0].set_yticklabels([f'{gamma_values[i]:.2f}' for i in gamma_tick_indices])\n",
    "\n",
    "plt.colorbar(im1, ax=axes[0], label='Match Count')\n",
    "\n",
    "# Overall community match count heatmap\n",
    "im2 = axes[1].imshow(overall_match_counts, cmap='viridis', aspect='auto', origin='lower')\n",
    "axes[1].set_title('Overall Community Match Count\\n(Gamma vs Tolerance)')\n",
    "axes[1].set_xlabel('Tolerance (epsilon)')\n",
    "axes[1].set_ylabel('Gamma')\n",
    "\n",
    "axes[1].set_xticks(tolerance_tick_indices)\n",
    "axes[1].set_xticklabels([f'{tolerance_range[i]:.2f}' for i in tolerance_tick_indices])\n",
    "axes[1].set_yticks(gamma_tick_indices)\n",
    "axes[1].set_yticklabels([f'{gamma_values[i]:.2f}' for i in gamma_tick_indices])\n",
    "\n",
    "plt.colorbar(im2, ax=axes[1], label='Match Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Create seaborn heatmaps for better aesthetics\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Create DataFrames for seaborn with proper indexing\n",
    "singular_df = pd.DataFrame(singular_match_counts, \n",
    "                          index=[f'{g:.3f}' for g in gamma_values],\n",
    "                          columns=[f'{t:.3f}' for t in tolerance_range])\n",
    "\n",
    "overall_df = pd.DataFrame(overall_match_counts,\n",
    "                         index=[f'{g:.3f}' for g in gamma_values], \n",
    "                         columns=[f'{t:.3f}' for t in tolerance_range])\n",
    "\n",
    "# Seaborn heatmaps with better formatting\n",
    "sns.heatmap(singular_df, ax=axes[0], cmap='viridis', cbar_kws={'label': 'Match Count'})\n",
    "axes[0].set_title('Singular Community Match Count\\n(Gamma vs Tolerance)')\n",
    "axes[0].set_xlabel('Tolerance (epsilon)')\n",
    "axes[0].set_ylabel('Gamma')\n",
    "\n",
    "# Show only every nth tick for readability\n",
    "n_display_ticks = 5\n",
    "gamma_display_ticks = range(0, len(gamma_values), len(gamma_values)//n_display_ticks)\n",
    "tolerance_display_ticks = range(0, len(tolerance_range), len(tolerance_range)//n_display_ticks)\n",
    "\n",
    "axes[0].set_xticks(tolerance_display_ticks)\n",
    "axes[0].set_xticklabels([f'{tolerance_range[i]:.2f}' for i in tolerance_display_ticks])\n",
    "axes[0].set_yticks(gamma_display_ticks)\n",
    "axes[0].set_yticklabels([f'{gamma_values[i]:.2f}' for i in gamma_display_ticks])\n",
    "\n",
    "sns.heatmap(overall_df, ax=axes[1], cmap='viridis', cbar_kws={'label': 'Match Count'})\n",
    "axes[1].set_title('Overall Community Match Count\\n(Gamma vs Tolerance)')\n",
    "axes[1].set_xlabel('Tolerance (epsilon)')\n",
    "axes[1].set_ylabel('Gamma')\n",
    "\n",
    "axes[1].set_xticks(tolerance_display_ticks)\n",
    "axes[1].set_xticklabels([f'{tolerance_range[i]:.2f}' for i in tolerance_display_ticks])\n",
    "axes[1].set_yticks(gamma_display_ticks)\n",
    "axes[1].set_yticklabels([f'{gamma_values[i]:.2f}' for i in gamma_display_ticks])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print some statistics about the results\n",
    "print(f\"\\nHeatmap Statistics:\")\n",
    "print(f\"Gamma range: {min(gamma_values):.3f} to {max(gamma_values):.3f}\")\n",
    "print(f\"Tolerance range: {min(tolerance_range):.3f} to {max(tolerance_range):.3f}\")\n",
    "print(f\"Singular match count range: {singular_match_counts.min():.0f} to {singular_match_counts.max():.0f}\")\n",
    "print(f\"Overall match count range: {overall_match_counts.min():.0f} to {overall_match_counts.max():.0f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
